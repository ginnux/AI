{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e2ae0d8a",
   "metadata": {},
   "source": [
    "# 多输入多输出深度学习时序预测模型\n",
    "## 1 常见时序预测分类\n",
    ">Broadly, these techniques can be grouped into three major groups: statistical methods, traditional machine learning-based methods, and deep learning-based methods.\n",
    "\n",
    "时序预测通常可以有三种方法：即统计学方法、传统机器学习、深度学习。\n",
    "- 统计学方法是根据现有数据拟合函数。\n",
    "- 传统机器学习即例如高斯过程、回归树等方法。\n",
    "- 深度学习可以自动的建立映射关系，包括CNN，RNN，LSTM。\n",
    "\n",
    "## 2 多步预测策略\n",
    "多步预测可分为四种方法，递归预测、直接预测、递归直接预测、多输入多输出预测。\n",
    "- 递归预测：${y_{t + H}} = {F_{{\\rm{Rec}}}}({y_{t + H - 1}},{y_{t + H - 2}},...,{y_{t + H - N}})$。用前N步的数据预测下一步，类似[RNN学习笔记](./循环神经网络笔记.ipynb)中的处理，然而输出的误差逐级积累。\n",
    "- 直接预测：${y_{t + h}} = {F_{{\\rm{Dir}}}}({x_t},{x_{t - 1}},...,{x_{t - N - 1}})$。用数据直接预测某一步的数据，这种方法没有考虑输出数据之间的时序关系。\n",
    "- 递归直接预测：$\\left\\{ {\\begin{array}{*{20}{c}}\n",
    "{{y_{t + 1}} = {F_{{\\rm{DirRec - 1}}}}({x_t},{x_{t - 1}},...,{x_{t - N + 1}})}\\\\\n",
    "{{y_{t + 2}} = {F_{{\\rm{DirRec - 2}}}}({y_{t + 1}},{x_t},{x_{t - 1}},...,{x_{t - N + 1}})}\\\\\n",
    " \\vdots \\\\\n",
    "{{y_{t + h}} = {F_{{\\rm{DirRec - h}}}}({y_{t + h - 1}},...,{y_{t + 1}},{x_t},{x_{t - 1}},...,{x_{t - N + 1}})}\\end{array}} \\right\\}$。它仍存在误差积累问题。\n",
    "- 多输入多输出预测：避免误差积累。\n",
    "\n",
    "## 3 LSTM 长短期记忆网络\n",
    ">Benefiting from the self-feedback mechanism, the recurrent\n",
    "neural network (RNN) model has advantages in exploring the\n",
    "temporal relationships in time series. However, it is more prone\n",
    "to gradient disappearance in practical applications. LSTM is\n",
    "designed to solve this problem on the basis of RNN, and\n",
    "thus with the ability to build long term dependencies.\n",
    "\n",
    "${\\Psi _t} = {\\rm{Sigmoid(}}{W_{x\\Psi }}{x_t}{\\rm{ + }}{W_{\\Psi h}}{h_{t - 1}} + {b_\\Psi }{\\rm{)(}}\\Psi {\\rm{ = }}f,i,o{\\rm{)}}$\n",
    "\\\n",
    "${g_t} = \\tanh ({W_{gx}}{x_t} + {W_{gh}}{h_{t - 1}} + {b_g})$\n",
    "\\\n",
    "${s_t} = {g_t} \\odot {i_t} + {s_{t - 1}} \\odot {f_t}$\n",
    "\\\n",
    "${h_t} = \\tanh ({s_t}) \\odot {o_t}$\n",
    "![img1](https://pic4.zhimg.com/v2-aa1eba31e6bca1d0a0076cf12ac3a0ab_r.jpg)\n",
    "## 4 TCN 时域卷积网络 （未清楚理解）\n",
    "- 因果卷积\n",
    "- 膨胀卷积\n",
    "- 残差连接\n",
    "\n",
    "## 5 拟合\n",
    "利用分解拟合的方法，用多个block去学习时间序列的特征。\n",
    "\n",
    "传统的方法可以将序列分成周期性、趋势性、余量三个部分分别拟合，而如果将block设置为超参数，更能适合不同的模型。它的优点是可以对复杂特征的时间序列进行特征提取。\n",
    "\n",
    "另外，通过多个LSTM组成神经元链，每一级LSTM同时接受本级输入与上一级残差，让网络更精确地拟合数据。（类似梯度增强的方法）\n",
    "## 6 代码"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6269ad0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.utils.data  \n",
    "import time\n",
    "import numpy as np\n",
    "import random\n",
    "import os\n",
    "import sys\n",
    "sys.path.append('..\\\\prepare_data')\n",
    "import prepare_data\n",
    "from model import stack\n",
    "from alive_progress import alive_bar\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# 定义超参数\n",
    "HyperParams = {'datapath':'..\\\\prepare_data\\\\data',      # 数据集路径\n",
    "               'datafile': 'AT',                         # 数据集文件\n",
    "               'split_ratio':[0.3, 0.1, 0.1],         # 数据集分割比例\n",
    "               \"batch_size\": 5120,\n",
    "               \"N_EPOCHS\": 2,\n",
    "               'lr': 5e-2,\n",
    "               \"features\": 3,\n",
    "               \"input_seqlen\": 12,\n",
    "               \"predict_seqlen\":60\n",
    "               }\n",
    "\n",
    "\n",
    "DEVICE = torch.device('cuda' if torch.cuda.is_available else 'cpu')\n",
    "torch.set_default_tensor_type('torch.DoubleTensor')\n",
    "path = os.getcwd()\n",
    "\n",
    "\n",
    "# 构建评估模型的类\n",
    "class MyMetrics:\n",
    "    def __init__(self, y_pred, y_true, un_std):\n",
    "        '''\n",
    "        y_hat.shape[samples, pred_horizion]\n",
    "        un_std : 类 DataPrepare 的实例 ，计算mape的时候需要反归一化\n",
    "        '''\n",
    "        self.un_std = un_std\n",
    "        self.y_pred = y_pred\n",
    "        self.y_true = y_true\n",
    "        self.metrics = {}\n",
    "        self.mse()\n",
    "        self.mape()\n",
    "        self.smape()\n",
    "\n",
    "    def mse(self):\n",
    "        self.metrics['mse'] = np.mean((self.y_pred - self.y_true) ** 2)\n",
    "\n",
    "    def mape(self):\n",
    "        y_pred = self.un_std.un_standardize(x=self.y_pred)\n",
    "        y_true = self.un_std.un_standardize(x=self.y_true)\n",
    "        self.metrics['mape'] = np.mean(np.abs((y_pred - y_true) / (y_true))) * 100\n",
    "\n",
    "    def smape(self):\n",
    "        self.metrics['smape'] = 2.0 * np.mean(\n",
    "            np.abs(self.y_pred - self.y_true) / (np.abs(self.y_pred) + np.abs(self.y_true))) * 100\n",
    "\n",
    "    def print_metrics(self):\n",
    "        for key, values in self.metrics.items():\n",
    "            print(f\"The {key} is:{values}.\")\n",
    "\n",
    "\n",
    "class Train:\n",
    "    def __init__(self, hyperparams, model, optimizer, loss_func):\n",
    "\n",
    "        # 数据集参数\n",
    "        self.datapath = hyperparams['datapath']\n",
    "        self.datafile = hyperparams['datafile']\n",
    "        self.split_ratio = hyperparams['split_ratio']\n",
    "\n",
    "        # 超参数\n",
    "        self.N_EPOCHS = hyperparams['N_EPOCHS']\n",
    "        self.lr = hyperparams['lr']\n",
    "        self.batch_size = hyperparams['batch_size']\n",
    "        self.input_seqlen = hyperparams['input_seqlen']\n",
    "        self.predict_seqlen = hyperparams['predict_seqlen']\n",
    "        self.features = hyperparams['features']\n",
    "\n",
    "        # 准备数据实例\n",
    "        self.dataprepare = prepare_data.DataPrepare(datapath=self.datapath,\n",
    "                                                    datafile=self.datafile,\n",
    "                                                    input_steps=self.input_seqlen,\n",
    "                                                    pred_horizion=self.predict_seqlen,\n",
    "                                                    split_ratio=self.split_ratio)\n",
    "\n",
    "        # 数据生成器\n",
    "        self.train_generator = None\n",
    "        self.valid_generator = None\n",
    "        self.test_generator = None\n",
    "\n",
    "        # 模型、优化器、损失函数\n",
    "        self.model = model\n",
    "        self.optimizer = optimizer\n",
    "        self.loss_func = loss_func\n",
    "\n",
    "        # 训练过程loss值\n",
    "        self.train_loss = []\n",
    "        self.valid_loss = []\n",
    "\n",
    "        # 训练完成后的损失值\n",
    "        self.mse = 0\n",
    "\n",
    "        # 自动设置 seed\n",
    "        self._setup_seed(20)\n",
    "        # 自动生成数据生成器\n",
    "        self._prepare_data()\n",
    "\n",
    "    def _prepare_data(self):\n",
    "        # tvt_data consist of (train_ip, train_op, valid_ip, valid_op, test_ip, test_op)\n",
    "\n",
    "        tvt_data = self.dataprepare.prepare_data()\n",
    "\n",
    "        train_dataset = prepare_data.Datasets(tvt_data[0], tvt_data[1])\n",
    "        valid_dataset = prepare_data.Datasets(tvt_data[2], tvt_data[3])\n",
    "        test_dataset = prepare_data.Datasets(tvt_data[4], tvt_data[5])\n",
    "\n",
    "        train_generator = torch.utils.data.DataLoader(dataset=train_dataset, batch_size=self.batch_size, shuffle=False)\n",
    "        valid_generator = torch.utils.data.DataLoader(dataset=valid_dataset, batch_size=self.batch_size, shuffle=False)\n",
    "        test_generator = torch.utils.data.DataLoader(dataset=test_dataset, batch_size=2048, shuffle=False)\n",
    "\n",
    "        self.train_generator = train_generator\n",
    "        self.valid_generator = valid_generator\n",
    "        self.test_generator = test_generator\n",
    "\n",
    "    def save_state(self, state, filepath=path + \"\\\\trained_file\"):\n",
    "        filename = filepath + '\\\\' + f'{self.datafile}-{self.input_seqlen}to{self.predict_seqlen}'\n",
    "        torch.save(state, filename)\n",
    "\n",
    "    def load_state(self, filepath=path + \"\\\\trained_file\"):\n",
    "        print(\"Loading model and optimizer state\")\n",
    "        filename = filepath + '\\\\' + f'{self.datafile}-{self.input_seqlen}to{self.predict_seqlen}'\n",
    "        self.model.load_state_dict(torch.load(filename)['model'])\n",
    "        self.optimizer.load_state_dict(torch.load(filename)['optimizer'])\n",
    "        self.train_loss = torch.load(filename)['train_loss']\n",
    "        self.valid_loss = torch.load(filename)['valid_loss']\n",
    "        self.mse = torch.load(filename)['mse']\n",
    "        self.dataprepare = torch.load(filename)['dataprepare']\n",
    "\n",
    "    def _train(self):\n",
    "        \"\"\"\n",
    "        params:\n",
    "                None\n",
    "        returns:\n",
    "            每个样本的平均损失值\n",
    "        \"\"\"\n",
    "        self.model.train()\n",
    "        epoch_loss = 0\n",
    "\n",
    "        for i, (x, y) in enumerate(self.train_generator):\n",
    "            x = x.to(DEVICE)  # [batch_size, seq_len, feature]\n",
    "            y = y.to(DEVICE)  # [batch_size, predict_seqlen]\n",
    "\n",
    "            self.optimizer.zero_grad()\n",
    "            # 输入到模型的是[batch_size, seq_len, features],模型输出是[batch_size,predict_seqlen, 1]\n",
    "            output, residual = self.model(x)\n",
    "            loss = self.loss_func(output.squeeze(dim=2), y) # + torch.mean(torch.abs(residual)) # output [batch_size, predict_seqlen]\n",
    "            loss.backward()\n",
    "            self.optimizer.step()\n",
    "            epoch_loss += loss.item()\n",
    "        # len(train_generator) 是 批次数量  即 样本总数/batch_size\n",
    "        return epoch_loss / len(self.train_generator)\n",
    "\n",
    "    def _evalute(self):\n",
    "        '''\n",
    "        模型评估函数\n",
    "        params:\n",
    "            无\n",
    "        return: 损失均值\n",
    "        '''\n",
    "        self.model.eval()\n",
    "        epoch_loss = 0\n",
    "        for i, (x, y) in enumerate(self.test_generator):\n",
    "            x = x.to(DEVICE)\n",
    "            y = y.to(DEVICE)\n",
    "            with torch.no_grad():\n",
    "                output,_ = self.model(x)  # output [batch_size, predict_seqlen, 1]\n",
    "                loss = self.loss_func(output.squeeze(dim=2), y)  # 计算mse\n",
    "                epoch_loss += loss.item()\n",
    "        return epoch_loss / len(self.test_generator)\n",
    "\n",
    "    def _epoch_time(self, start_time, end_time):\n",
    "        '''\n",
    "        function: calculate the time of every epoch\n",
    "        params:\n",
    "            start_time:\n",
    "            end_time\n",
    "        return:\n",
    "            elapsed_mins:\n",
    "            elapsed_secs:\n",
    "        '''\n",
    "        elapsed_time = end_time - start_time\n",
    "        elapsed_mins = int(elapsed_time / 60)\n",
    "        elapsed_secs = int(elapsed_time - elapsed_mins * 60)\n",
    "        return elapsed_mins, elapsed_secs\n",
    "\n",
    "    def _setup_seed(self, seed):\n",
    "        # 初始化随机种子\n",
    "        torch.manual_seed(seed)\n",
    "        torch.cuda.manual_seed_all(seed)\n",
    "        np.random.seed(seed)\n",
    "        random.seed(seed)\n",
    "        torch.backends.cudnn.deterministic = True\n",
    "\n",
    "    def train_model(self):\n",
    "        # 初始最佳loss值为无穷大\n",
    "        best_valid_loss = float('inf')\n",
    "        print(f'DEVICE:{DEVICE}')\n",
    "        # 训练进度条\n",
    "        with alive_bar(total=self.N_EPOCHS, title='training') as bar:\n",
    "            for epoch in range(self.N_EPOCHS):\n",
    "                # 记录开始时间\n",
    "                start_time = time.time()\n",
    "\n",
    "                # 训练评估\n",
    "                train_loss = self._train()\n",
    "                valid_loss = self._evalute()\n",
    "\n",
    "                # 将 训练评估值保存起来\n",
    "                self.train_loss.append(train_loss)\n",
    "                self.valid_loss.append(valid_loss)\n",
    "\n",
    "                # 记录结束时间\n",
    "                end_time = time.time()\n",
    "                # 计算 分钟、秒\n",
    "                epoch_mins, epoch_secs = self._epoch_time(start_time, end_time)\n",
    "\n",
    "                # 保存最好的模型\n",
    "                if best_valid_loss > valid_loss:\n",
    "                    best_valid_loss = valid_loss  # 更新最优值\n",
    "                    self.mse = valid_loss  # 更新最优值\n",
    "                    my_state = {'model': self.model.state_dict(),\n",
    "                                \"optimizer\": self.optimizer.state_dict(),\n",
    "                                \"train_loss\": self.train_loss,\n",
    "                                \"valid_loss\": self.valid_loss,\n",
    "                                'dataprepare': self.dataprepare,\n",
    "                                \"mse\": self.mse, }\n",
    "                    self.save_state(state=my_state)\n",
    "\n",
    "                # 打印该epoch训练信息\n",
    "                print(f'Epoch: {epoch + 1:02} | Time: {epoch_mins}m {epoch_secs}s')\n",
    "                print(f'\\tTrain MSE_Loss: {train_loss:.4f}')\n",
    "                print(f'\\t Val. MSE_Loss: {valid_loss:.4f}')\n",
    "\n",
    "                # 更新进度条\n",
    "                bar()\n",
    "\n",
    "    def evaluate_model(self):\n",
    "        pass\n",
    "\n",
    "    def plot_loss(self, save: bool = False):\n",
    "        # x = [i for i in np.linspace(0,self.N_EPOCHS)]\n",
    "        fig = plt.figure(num=1, figsize=(15, 8), dpi=80)  # 开启一个窗口，同时设置大小，分辨率\n",
    "        ax1 = fig.add_subplot(1, 1, 1)  # 通过fig添加子图，参数：行数，列数，第几个\n",
    "        ax1.set_title('loss_value')  # 设置图体，plt.title\n",
    "        ax1.set_xlabel('epoch')  # 设置x轴名称,plt.xlabel\n",
    "        ax1.set_ylabel('loss')  # 设置y轴名称,plt.ylabel\n",
    "        ax1.set_xlim(0, self.N_EPOCHS)  # 设置横轴范围，会覆盖上面的横坐标,plt.xlim\n",
    "        # ax1.set_ylim(0,3)                         #设置纵轴范围，会覆盖上面的纵坐标,plt.ylim\n",
    "        plot1 = ax1.plot(self.train_loss, marker='o', color='g', label='train_loss')  # 点图：marker图标\n",
    "        plot2 = ax1.plot(self.valid_loss, linestyle='--', alpha=0.5, color='r',\n",
    "                         label='valid_loss')  # 线图：linestyle线性，alpha透明度，color颜色，label图例文本\n",
    "        ax1.legend(loc='upper left')  # 显示图例,plt.legend()\n",
    "        if save:\n",
    "            plt.savefig('loss_value.jpg', dpi=400, bbox_inches='tight')  # savefig保存图片，dpi分辨率，bbox_inches子图周边白色空间的大小\n",
    "        plt.show()\n",
    "\n",
    "    def show_example(self):\n",
    "        '''\n",
    "        展示训练后的模型在一个样本上的预测能力\n",
    "        以 test_generation 的第一个样本为例\n",
    "        '''\n",
    "        for x, y in self.test_generator:\n",
    "            x = x.to(DEVICE)  # [batch_size, seqlen,  feature]\n",
    "            y = y.to(DEVICE)  # [batch_size, predict_seqlen, 1]\n",
    "            break\n",
    "        # 取第一个批次的第一个样本\n",
    "        inputs = x[0].unsqueeze(dim=0)  # [batch_size=1, seqlen, feature]\n",
    "        target = y[0]  # [seq_len=predict_seqlen, feature=1]\n",
    "\n",
    "        pred = self.predict(inputs)  # [batch_szie=1, predict_seqlen, features]\n",
    "        pred = pred.squeeze(dim=0)  # [predict_seqlen, features=1]\n",
    "        fig = plt.figure()\n",
    "\n",
    "        # 将输入和 target 合并一起\n",
    "        inputs_targets = torch.cat((inputs[:, :, 0].squeeze(dim=0), target.reshape(-1)))\n",
    "        # 将输入和 pred 合并一起\n",
    "        inputs_pred = torch.cat((inputs[:, :, 0].squeeze(dim=0), pred.reshape(-1)))\n",
    "\n",
    "        # 在预测的点上做标记\n",
    "        markers_on = np.arange(pred.shape[0]) + inputs.shape[1]  # 14 + [0,1,2,3]\n",
    "\n",
    "        plt.plot(inputs_targets.cpu().numpy().reshape(-1), label=\"target\")\n",
    "        plt.plot(inputs_pred.cpu().numpy().reshape(-1), label=\"pred\", marker='D', markevery=markers_on)\n",
    "        plt.legend()\n",
    "        plt.show()\n",
    "\n",
    "    def predict(self):\n",
    "        '''\n",
    "        :return:  y_hay , y\n",
    "        '''\n",
    "        self.model.eval()\n",
    "        with torch.no_grad():\n",
    "            for i, (x, y) in enumerate(self.test_generator):\n",
    "                x = x.to(DEVICE)  # [batch_size, seq_len, feature]\n",
    "                y = y.to(DEVICE)  # [batch_size, predict_seqlen]\n",
    "                y_hat, _ = self.model(x)  # y_hat [batch_size, predict_seqlen, 1]\n",
    "                y_hat = y_hat.squeeze(dim=2)\n",
    "                break  # 测试集批次为1024，只测试这1024个样本\n",
    "\n",
    "        return y_hat.cpu().numpy(), y.cpu().numpy()\n",
    "\n",
    "\n",
    "def main():\n",
    "    # 是否加载模型\n",
    "    load_model = False\n",
    "\n",
    "    # 模型 优化器 损失函数\n",
    "    model = stack.Stack(input_size=HyperParams['features'],\n",
    "                        encoder_channels=[4, 6],\n",
    "                        input_seqlen=HyperParams['input_seqlen'],\n",
    "                        forecast_seqlen=HyperParams['predict_seqlen']).to(DEVICE)\n",
    "\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=HyperParams['lr'])\n",
    "    loss_func = torch.nn.MSELoss(reduction='mean')\n",
    "\n",
    "    T = Train(hyperparams=HyperParams, model=model, optimizer=optimizer, loss_func=loss_func)\n",
    "    if load_model:\n",
    "        T.load_state()  # 加载之前训练好的模型\n",
    "        T.train_model() # 再训练一次\n",
    "    else:\n",
    "        T.train_model()\n",
    "\n",
    "    # 评估模型\n",
    "    y_hat, y = T.predict()\n",
    "    mymetrics = MyMetrics(y_hat, y, T.dataprepare)\n",
    "    mymetrics.print_metrics()\n",
    "    T.plot_loss()\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "     main()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "314f1387",
   "metadata": {},
   "source": [
    "## 7 错误？\n",
    "```\n",
    "Traceback (most recent call last):\n",
    "  File \"C:\\Users\\coldwarrior\\Downloads\\Novel-Seq2Seq-Module-master\\Novel-Seq2Seq-Module-master\\Novel_Seq2Seq\\main.py\", line 345, in <module>\n",
    "    main()\n",
    "  File \"C:\\Users\\coldwarrior\\Downloads\\Novel-Seq2Seq-Module-master\\Novel-Seq2Seq-Module-master\\Novel_Seq2Seq\\main.py\", line 340, in main\n",
    "    T.show_example()\n",
    "  File \"C:\\Users\\coldwarrior\\Downloads\\Novel-Seq2Seq-Module-master\\Novel-Seq2Seq-Module-master\\Novel_Seq2Seq\\main.py\", line 281, in show_example\n",
    "    pred = self.predict(inputs)  # [batch_szie=1, predict_seqlen, features]\n",
    "TypeError: Train.predict() takes 1 positional argument but 2 were given\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d507043",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 310",
   "language": "python",
   "name": "python310"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
